{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import pathogenprofiler as pp\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, f1_score\n",
    "# import fastq2matrix as fm\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import json\n",
    "from scipy.stats import norm\n",
    "import subprocess\n",
    "from scipy.stats import kurtosis, skew\n",
    "import re\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_file = 'test_data/ERR6634978-ERR6635032-2080.vcf.gz'\n",
    "json_file = 'test_data/ERR6634978-ERR6635032-2080.results.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "VCF_FILE_PATH='/mnt/storage7/lwang/trial_tb_philippines/data/processed/seqtk/freebayesVCF/q20'\n",
    "#/mnt/storage7/lwang/trial_tb_philippines/data/processed/seqtk/freebayesVCF/q20\n",
    "JSON_FILE_PATH='/mnt/storage7/lwang/trial_tb_philippines/data/processed/seqtk/freebayesVCF/q20/results'\n",
    "#/mnt/storage7/lwang/trial_tb_philippines/data/processed/seqtk/freebayesVCF/q20/results\n",
    "\n",
    "NAME_FILE='/mnt/storage7/lwang/trial_tb_philippines/data/seqtk/sample_name.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_variant_to_distrib(gm,freq,cutoff=0.95):\n",
    "    probs = gm.predict_proba([[freq]])\n",
    "    pred = gm.predict([[freq]])\n",
    "    if probs[0][pred][0]>cutoff:\n",
    "        return pred[0], probs[0][pred][0]\n",
    "    else:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
    "        return None, pred[0], probs[0][pred][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0.7554125219426565, 0.20933977455716588], 0.10466988727858294)\n"
     ]
    }
   ],
   "source": [
    "tb_profiler_predictions = []\n",
    "\n",
    "def tb_profiler_pred(json_file):\n",
    "    output = []\n",
    "    json_results = json.load(open(json_file))\n",
    "    for x in json_results['lineage']:\n",
    "        if re.search(\"^lineage1.2.1$\", x['lin']):\n",
    "            output.append(x['frac'])\n",
    "        if re.search(\"^lineage4.3.4$\", x['lin']):\n",
    "            output.append(x['frac'])\n",
    "        \n",
    "    if len(output) == 1:\n",
    "        output.append(0)\n",
    "    if output[0] < output[1]:\n",
    "        temp = output[0]\n",
    "        output[0] = output[1]\n",
    "        output[1] = temp\n",
    "    if output[0] > output[1]:\n",
    "        cut_off =  output[1]/2\n",
    "    else:\n",
    "        cut_off =  output[-2]/2\n",
    "\n",
    "    return output, cut_off\n",
    "\n",
    "\n",
    "print(tb_profiler_pred(json_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0.813039174872355, 0.22337684271188749], GaussianMixture(n_components=2, random_state=0))\n"
     ]
    }
   ],
   "source": [
    "model_predictions = []\n",
    "\n",
    "def model_pred(vcf_file, tail_cutoff=0.00):\n",
    "    with open('mix_infection.csv', 'w') as f:\n",
    "        subprocess.run(\"bcftools view -c 1 -m2 -M2 -T ^new_exclusion.bed %s | bcftools query -f '%%POS\\\\t%%REF\\\\t%%ALT[\\\\t%%GT\\\\t%%AD\\\\n]'\" % vcf_file, shell=True, stdout=f, text=True)\n",
    "\n",
    "#count how many column there is in the ROAO_proportion.csv file this is needed in order to read the csv in a a panda dataframe\n",
    "    pos = []\n",
    "    freqs = []\n",
    "    with open('mix_infection.csv', 'r') as f:\n",
    "        for l in f:\n",
    "            row = l.strip().split()\n",
    "            ads = [int(x) for x in row[4].split(\",\")]\n",
    "            afs = [x/sum(ads) for x in ads]\n",
    "            if afs[1]>1-tail_cutoff or afs[1]<tail_cutoff:\n",
    "                continue\n",
    "            pos.append(int(row[0]))\n",
    "            freqs.append([afs[1]])\n",
    "        # freqs = [[0.7],[0.6],[0.4]]    \n",
    "        gm = GaussianMixture(n_components=2, random_state=0).fit(freqs)\n",
    "        mu0 = gm.means_[1][0]\n",
    "        mu1 = gm.means_[0][0]\n",
    "    if mu0 > mu1:\n",
    "        return [mu0, mu1], gm\n",
    "    else:\n",
    "        return [mu1, mu0], gm\n",
    "\n",
    "\n",
    "print(model_pred(vcf_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frac_MSE(NAME_FILE=NAME_FILE, JSON_FILE_PATH=JSON_FILE_PATH, VCF_FILE_PATH=VCF_FILE_PATH):\n",
    "    with open(NAME_FILE, 'r') as f:\n",
    "        sample_list = [line.rstrip('\\n') for line in f]\n",
    "\n",
    "    sample_list_json=[]\n",
    "    for i,x in enumerate(sample_list):\n",
    "        x = list(x)\n",
    "        x.append('.results.json')\n",
    "        string = ''.join([letter for letter in x] )\n",
    "        sample_list_json.append(string)\n",
    "    \n",
    "\n",
    "    sample_list_vcf=[]\n",
    "    for i,x in enumerate(sample_list):\n",
    "        x = list(x)\n",
    "        x.append('_q20.recode.vcf.gz')  #change here if using filtered/non-filtered samples\n",
    "        string = ''.join([letter for letter in x] )\n",
    "        sample_list_vcf.append(string)\n",
    "\n",
    "    ratio = []\n",
    "    for i in sample_list_json:\n",
    "        temp = i.split('-')\n",
    "        ratio.append(temp[2])\n",
    "    \n",
    "    ratio1=[]\n",
    "    for i in ratio:\n",
    "        temp = i.split('.')\n",
    "        ratio1.append(temp[0])\n",
    "\n",
    "    ratio = ratio1\n",
    "\n",
    "    tb_profiler_predictions = []\n",
    "    model_predictions = []\n",
    "\n",
    "    for j, vcf, ratio in zip(sample_list_json, sample_list_vcf, ratio):\n",
    "        JSON_FILE = os.path.join(JSON_FILE_PATH, j)\n",
    "        tb_out_, cut_off = tb_profiler_pred(JSON_FILE)\n",
    "\n",
    "        VCF_FILE = os.path.join(VCF_FILE_PATH, vcf)\n",
    "        model_out_, gm = model_pred(vcf_file, tail_cutoff=cut_off)\n",
    "\n",
    "        tb_profiler_predictions.extend(tb_out_)\n",
    "        model_predictions.extend(model_out_)\n",
    "    \n",
    "    print(tb_profiler_predictions)\n",
    "    print(model_predictions)\n",
    "    MSE = mean_squared_error(tb_profiler_predictions, model_predictions, squared=False)\n",
    "\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9974779319041615, 0, 0.9240583232077765, 0, 0.9949452401010952, 0, 0.8633651551312649, 0, 0.8129839189994044, 0.141399416909621, 0.7554125219426565, 0.20933977455716588, 0.7028862478777589, 0.24958263772954925, 0.6681818181818182, 0.2986167615947925, 0.6272257323377369, 0.34077750206782464, 0.5873648264086511, 0.3963963963963964, 0.5228684359119141, 0.45028294260307195, 0.5011990407673861, 0.47477064220183485, 0.5432196669310071, 0.43852691218130313, 0.5932203389830508, 0.38841567291311757, 0.6541598694942904, 0.33860045146726864, 0.6951219512195121, 0.2962962962962963, 0.7464788732394366, 0.24119076549210205, 0.7953216374269005, 0.20209287115761937, 0.846089850249584, 0.15904292751583393, 0.9061461794019934, 0.07450980392156863, 0.9465776293823038, 0]\n",
      "[0.813039174872355, 0.22337684271188749, 0.813039174872355, 0.22337684271188749, 0.813039174872355, 0.22337684271188749, 0.813039174872355, 0.22337684271188749, 0.7660500659768188, 0.23408824816297552, 0.7659220199852712, 0.2368329200364438, 0.7654313382080861, 0.24062434978518157, 0.7633326746158897, 0.248175728926683, 0.7594994936010414, 0.2563479980812515, 0.7502904174077132, 0.2759160643977226, 0.7345189680886, 0.3050689367897097, 0.7268216992632079, 0.3190932149543465, 0.7386749204957458, 0.29749997759349367, 0.7520835761491568, 0.2726061158130421, 0.7596499118841945, 0.2558614786549246, 0.7637465557502369, 0.24760025372757327, 0.765725871232473, 0.23977047810870794, 0.7659407877428647, 0.23550167284822052, 0.7660500659768188, 0.23408824816297552, 0.7660500659768188, 0.23408824816297552, 0.813039174872355, 0.22337684271188749]\n",
      "0.13491805193613485\n"
     ]
    }
   ],
   "source": [
    "print(frac_MSE(NAME_FILE=NAME_FILE, JSON_FILE_PATH=JSON_FILE_PATH, VCF_FILE_PATH=VCF_FILE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08232703363298553"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing the 0100 and 1000 6040, 5050case\n",
    "y_true = [0.8633651551312649, 0.1011378002528445, 0.7554125219426565, 0.20933977455716588, 0.6681818181818182, 0.2986167615947925, \n",
    "          # 0.5873648264086511, 0.3963963963963964, 0.5011990407673861, 0.47477064220183485, 0.5932203389830508, 0.38841567291311757, \n",
    "          0.6951219512195121, 0.2962962962962963, 0.7953216374269005, 0.20057803468208094, 0.9061461794019934, 0.12028608582574772]\n",
    "y_pred = [0.7660500659768188, 0.23408824816297552, 0.7659220199852712, 0.2368329200364438, 0.7633326746158897, 0.248175728926683, \n",
    "          # 0.7502904174077132, 0.2759160643977226, 0.7268216992632079, 0.3190932149543465, 0.7520835761491568, 0.2726061158130421, \n",
    "          0.7637465557502369, 0.24760025372757327, 0.7659445772369651, 0.2352338544977916, 0.7660500659768188, 0.23408824816297552]\n",
    "print(len(y_true))\n",
    "print(len(y_pred))\n",
    "mean_squared_error(y_true, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_map(y, y_pred, title):\n",
    "    cf_matrix = confusion_matrix(y, y_pred)\n",
    "    \n",
    "    group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                    cf_matrix.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                         cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "    labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_mat(NAME_FILE=NAME_FILE, JSON_FILE_PATH=JSON_FILE_PATH, VCF_FILE_PATH=VCF_FILE_PATH, output=False):\n",
    "    with open(NAME_FILE, 'r') as f:\n",
    "        sample_list = [line.rstrip('\\n') for line in f]\n",
    "\n",
    "    sample_list_json=[]\n",
    "    for i,x in enumerate(sample_list):\n",
    "        x = list(x)\n",
    "        x.append('.results.json')\n",
    "        string = ''.join([letter for letter in x] )\n",
    "        sample_list_json.append(string)\n",
    "        \n",
    "    sample_list_vcf=[]\n",
    "    for i,x in enumerate(sample_list):\n",
    "        x = list(x)\n",
    "        x.append('.vcf.gz')\n",
    "        string = ''.join([letter for letter in x] )\n",
    "        sample_list_vcf.append(string)\n",
    "\n",
    "    ratio = []\n",
    "    for i in sample_list_json:\n",
    "        temp = i.split('-')\n",
    "        ratio.append(temp[2])\n",
    "    \n",
    "    ratio1=[]\n",
    "    for i in ratio:\n",
    "        temp = i.split('.')\n",
    "        ratio1.append(temp[0])\n",
    "\n",
    "    ratio = ratio1\n",
    "\n",
    "    pos_lin_0 = {'rifampicin':0, 'isoniazid':1, 'ethambutol':2}\n",
    "    pos_lin_1 = {'rifampicin':0, 'streptomycin':1, 'isoniazid':2, 'ethionamide':3}\n",
    "    \n",
    "    ratio_list = []\n",
    "    f1_list = []\n",
    "\n",
    "\n",
    "\n",
    "    for j, vcf, ratio in zip(sample_list_json, sample_list_vcf, ratio):\n",
    "        JSON_FILE = os.path.join(JSON_FILE_PATH, j)\n",
    "        tb_out_, cut_off = tb_profiler_pred(JSON_FILE)\n",
    "\n",
    "        if ratio == '0100': \n",
    "            lin_ = [0,0,0,1,1,1,1] #lineage1 with rifampicin, streptomycin, isoniazid, ethionamide resistance\n",
    "        elif ratio == '1000':\n",
    "            lin_ = [1,1,1,0,0,0,0] #lineage4 with rifampicin, isoniazid, ethambutol resistance\n",
    "        else:\n",
    "            lin_ = [1,1,1,1,1,1,1]\n",
    "\n",
    "\n",
    "        VCF_FILE = os.path.join(VCF_FILE_PATH, vcf)\n",
    "        model_out_, gm = model_pred(vcf_file, tail_cutoff=cut_off)\n",
    "\n",
    "        strain0 = []\n",
    "        strain1 = []\n",
    "        strainU = []\n",
    "\n",
    "        json_results = json.load(open(JSON_FILE))\n",
    "        for var in json_results['dr_variants']:\n",
    "            cluster = assign_variant_to_distrib(gm,var['freq'], cutoff=0.95)\n",
    "            if cluster[0] == 0:\n",
    "                var['probs']= cluster\n",
    "                strain0.append(var)\n",
    "            elif cluster[0] == 1:\n",
    "                var['probs']= cluster\n",
    "                strain1.append(var)\n",
    "            else:\n",
    "                var['probs']= cluster[1:]\n",
    "                strainU.append(var)\n",
    "\n",
    "\n",
    "        strain_0 = [(v['drugs'][0]['drug']) for v in strain0]\n",
    "        strain_1 = [(v['drugs'][0]['drug']) for v in strain1]\n",
    "        \n",
    "        # print(ratio)\n",
    "        # print(strain_0)\n",
    "        # print(strain_1)\n",
    "        \n",
    "        if 'ethambutol' in strain_1:\n",
    "            strain_0 = [(v['drugs'][0]['drug']) for v in strain1]\n",
    "            strain_1 = [(v['drugs'][0]['drug']) for v in strain0]\n",
    "\n",
    "        if 'streptomycin' in strain_0 or 'ethionamide' in strain_0:\n",
    "            strain_1 = [(v['drugs'][0]['drug']) for v in strain0]\n",
    "            strain_0 = [(v['drugs'][0]['drug']) for v in strain1]\n",
    "\n",
    "        # strain_0 = list(set(strain_0))\n",
    "        # strain_1 = list(set(strain_1))\n",
    "        \n",
    "        # print(ratio)\n",
    "        # print(strain_0)\n",
    "        # print(strain_1)\n",
    "        \n",
    "        strain_0_pred = [0]*3\n",
    "        if 'streptomycin' in strain_0 or 'ethionamide' in strain_0:\n",
    "            print(ratio,'strain_0_error', strain_0)\n",
    "        else:\n",
    "            for d in strain_0:\n",
    "                strain_0_pred[pos_lin_0[d]] = 1\n",
    "\n",
    "        strain_1_pred = [0]*4\n",
    "        if 'ethambutol' in strain_1:\n",
    "            print(ratio,'strain_1_error', strain_1)\n",
    "        else:\n",
    "            for d in strain_1:\n",
    "                strain_1_pred[pos_lin_1[d]] = 1\n",
    "        \n",
    "        strain_pred = []\n",
    "        strain_pred.extend(strain_0_pred)\n",
    "        strain_pred.extend(strain_1_pred)\n",
    "        f1 = f1_score(lin_, strain_pred)\n",
    "        if output == True:\n",
    "            confusion_map(lin_, strain_pred, ratio)\n",
    "            print(f'f1-{ratio}:', f1)\n",
    "        \n",
    "        # print(lin_)\n",
    "        # print(strain_pred)\n",
    "\n",
    "\n",
    "        \n",
    "        ratio_list.append(ratio)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    return ratio_list, f1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat(NAME_FILE=NAME_FILE, JSON_FILE_PATH=JSON_FILE_PATH, VCF_FILE_PATH=VCF_FILE_PATH, output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_f1_bar(ratio, f1):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=ratio ,y=f1, mode='lines',))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"F1 score\",\n",
    "        xaxis_title=\"Strain Ratio\",\n",
    "        yaxis_title=\"F1\",\n",
    "        legend_title=\"\",\n",
    "        font=dict(\n",
    "            family=\"Courier New, monospace\",\n",
    "            size=18,\n",
    "            color=\"RebeccaPurple\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "ratio, f1 = confusion_mat(NAME_FILE=NAME_FILE, JSON_FILE_PATH=JSON_FILE_PATH, VCF_FILE_PATH=VCF_FILE_PATH)    \n",
    "\n",
    "plot_f1_bar(ratio, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gm(gm,data):\n",
    "    gm.covariances_[0][0][0]\n",
    "    std0 = np.sqrt(gm.covariances_[0][0][0]) #(n_components, n_features, n_features)\n",
    "    print('std0:',std0)\n",
    "    mu0 = gm.means_[0][0]\n",
    "    print(mu0)\n",
    "    std1 = np.sqrt(gm.covariances_[1][0][0]) #component 1?\n",
    "    print('std1:',std1)\n",
    "    mu1 = gm.means_[1][0]\n",
    "    print(mu1)\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    p0 = norm.pdf(x, mu0, std0)\n",
    "    p1 = norm.pdf(x, mu1, std1)\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    fig.add_trace(go.Histogram(x=[x[0] for x in data]),secondary_y=False)\n",
    "    fig.add_trace(go.Scatter(x=x, y=p0, mode='lines'),secondary_y=True)\n",
    "    fig.add_trace(go.Scatter(x=x, y=p1, mode='lines'),secondary_y=True)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gaussian():\n",
    "    pos = []\n",
    "    freqs = []\n",
    "    with open('mix_infection.csv', 'w') as f:\n",
    "        subprocess.run(\"bcftools view -c 1 -m2 -M2 -T ^new_exclusion.bed %s | bcftools query -f '%%POS\\\\t%%REF\\\\t%%ALT[\\\\t%%GT\\\\t%%AD\\\\n]'\" % vcf_file, shell=True, stdout=f, text=True)\n",
    "\n",
    "#count how many column there is in the ROAO_proportion.csv file this is needed in order to read the csv in a a panda dataframe\n",
    "\n",
    "    with open('mix_infection.csv', 'r') as f:\n",
    "        for l in f:\n",
    "            row = l.strip().split()\n",
    "            ads = [int(x) for x in row[4].split(\",\")]\n",
    "            afs = [x/sum(ads) for x in ads]\n",
    "            pos.append(int(row[0]))\n",
    "            freqs.append([afs[1]])\n",
    "\n",
    "        mean_ = np.mean([x[0] for x in freqs])\n",
    "        std_ = np.std([x[0] for x in freqs])\n",
    "        print('mean:', mean_)\n",
    "        print('std:', std_)\n",
    "        print('2sd up', mean_-2*std_)\n",
    "        print('2sd down', mean_+2*std_)\n",
    "\n",
    "        print('skew:', skew([x[0] for x in freqs]))\n",
    "        print('kurtosis:', kurtosis([x[0] for x in freqs]))\n",
    "\n",
    "\n",
    "        fig = make_subplots()\n",
    "        fig.add_trace(go.Histogram(x=[x[0] for x in freqs]),secondary_y=False)\n",
    "        fig.add_vline(mean_-2*std_, line_dash='dash',line_color='red')\n",
    "        fig.add_vline(mean_+2*std_, line_dash='dash',line_color='red')\n",
    "\n",
    "        fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gaussian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vcf_to_mix_model(vcf_file,plot=False,tail_cutoff=0.05,title=\"AF Histogram\",return_freqs = False):\n",
    "    pos = []\n",
    "    freqs = []\n",
    "    with open('mix_infection.csv', 'w') as f:\n",
    "        subprocess.run(\"bcftools view -c 1 -m2 -M2 -T ^new_exclusion.bed %s | bcftools query -f '%%POS\\\\t%%REF\\\\t%%ALT[\\\\t%%GT\\\\t%%AD\\\\n]'\" % vcf_file, shell=True, stdout=f, text=True)\n",
    "\n",
    "#count how many column there is in the ROAO_proportion.csv file this is needed in order to read the csv in a a panda dataframe\n",
    "\n",
    "    with open('mix_infection.csv', 'r') as f:\n",
    "        for l in f:\n",
    "            row = l.strip().split()\n",
    "            ads = [int(x) for x in row[4].split(\",\")]\n",
    "            afs = [x/sum(ads) for x in ads]\n",
    "            if afs[1]>1-tail_cutoff or afs[1]<tail_cutoff:\n",
    "                continue\n",
    "            pos.append(int(row[0]))\n",
    "            freqs.append([afs[1]])\n",
    "        # freqs = [[0.7],[0.6],[0.4]]    \n",
    "    gm = GaussianMixture(n_components=2, random_state=0).fit(freqs)\n",
    "    if plot:\n",
    "        plot_gm(gm,freqs)\n",
    "    if return_freqs:\n",
    "        return (gm,list(zip(pos,freqs)))\n",
    "    else:\n",
    "        return gm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = vcf_to_mix_model(vcf_file,plot=True,tail_cutoff=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_results = json.load(open(json_file))\n",
    "strain0 = []\n",
    "strain1 = []\n",
    "strainU = []\n",
    "\n",
    "for var in json_results['dr_variants']:\n",
    "    cluster = assign_variant_to_distrib(gm,var['freq'])\n",
    "    if cluster[0] == 0:\n",
    "        var['probs']= cluster\n",
    "        strain0.append(var)\n",
    "    elif cluster[0] == 1:\n",
    "        var['probs']= cluster\n",
    "        strain1.append(var)\n",
    "    else:\n",
    "        var['probs']= cluster[1:]\n",
    "        strainU.append(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([(v['gene'],v['change'],v['freq'],v['probs']) for v in strain0])\n",
    "for x in strain0:\n",
    "    for y in x['drugs']:\n",
    "        print(y['drug'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([(v['gene'],v['change'],v['freq'],v['probs']) for v in strain1])\n",
    "for x in strain1:\n",
    "    for y in x['drugs']:\n",
    "        print(y['drug'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print([(v['gene'],v['change'],v['freq'],v['probs']) for v in strainU])\n",
    "for x in strainU:\n",
    "    for y in x['drugs']:\n",
    "        print(y['drug'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
